{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Recall the overall workflow for retrieval augmented generation (RAG):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./img/RAG.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discussed `Document Loading` and `Splitting` as well as `Storage` and `Retrieval`.\n",
    "\n",
    "Let's load our vectorDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "llm_name = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "persist_directory = \"docs/chroma/\"\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of docs:  3\n"
     ]
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question, k=3)\n",
    "print(\"Length of docs: \", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The major topics for this class include machine learning, statistics, and algebra. Additionally, there will be discussions on extensions of the material covered in the main lectures.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \\\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer. \\\n",
    "    Use three sentences maximum. Keep the answer as concise as possible. \\\n",
    "    Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  Yes, probability is a class topic as the instructor assumes familiarity with basic probability and statistics. Thanks for asking!\n",
      "Source:  docs/cs229_lectures/MachineLearning-Lecture01.pdf\n"
     ]
    }
   ],
   "source": [
    "print(\"Result: \", result[\"result\"])\n",
    "print(\"Source: \", result[\"source_documents\"][0].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA chain types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm, retriever=vectordb.as_retriever(), chain_type=\"map_reduce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain_mr.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  Yes, probability is a class topic in the document.\n"
     ]
    }
   ],
   "source": [
    "print(\"Result: \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ignore this one for now\n",
    "If you wish to experiment on the `LangChain plus platform`:\n",
    "\n",
    " * Go to [LangchainSmith](https://www.langchain.com/langsmith) and sign up\n",
    " * Create an API key from your account's settings\n",
    " * Use this API key in the code below   \n",
    " * uncomment the code  \n",
    " Note, the endpoint in the video differs from the one below. Use the one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  The prerequisites of basic computer science knowledge, probability and statistics, and linear algebra are needed for the class to ensure that students have the foundational knowledge required to understand and apply the advanced concepts and techniques of machine learning that will be taught in the course.\n"
     ]
    }
   ],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm, retriever=vectordb.as_retriever(), chain_type=\"map_reduce\"\n",
    ")\n",
    "result = qa_chain_mr.invoke({\"query\": question})\n",
    "print(\"Result: \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  The additional context provided does not significantly impact the original answer, as it still remains clear that probability is a class topic in the course being discussed. The mention of using probability concepts to derive the next learning algorithm and the importance of probability in understanding classification problems are still relevant. Therefore, the original answer stands as an appropriate response to the question.\n"
     ]
    }
   ],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm, retriever=vectordb.as_retriever(), chain_type=\"refine\"\n",
    ")\n",
    "result = qa_chain_mr.invoke({\"query\": question})\n",
    "print(\"Result: \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA limitations\n",
    " \n",
    "QA fails to preserve conversational history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  Yes, probability is a class topic mentioned in the context provided. The instructor assumes familiarity with basic probability and statistics for the class.\n"
     ]
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "print(\"Result: \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  The prerequisites of basic knowledge in computer science, probability and statistics, and linear algebra are needed for the machine learning class because they form the foundational understanding required to grasp the concepts and algorithms taught in the course. Understanding these subjects helps students apply machine learning algorithms effectively to real-world problems and conduct research in the field.\n"
     ]
    }
   ],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "print(\"Result: \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, The LLM response varies. Some responses **do** include a reference to probability which might be gleaned from referenced documents. The point is simply that the model does not have access to past questions or answers, this will be covered in the next section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
